{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db2da9d",
   "metadata": {},
   "source": [
    "### Test data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a870f8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\STACKER BEE\\\\Image classification using CNN'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94a219e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "# main_data_dir = r'E:\\STACKER BEE\\Image classification using CNN\\image zip file\\tgv3zb82nd-1'\n",
    "# samples_data_dir = r'E:\\STACKER BEE\\Image classification using CNN\\Sample Data'\n",
    "# test_data_dir = r'E:\\STACKER BEE\\Image classification using CNN\\Test Data'\n",
    "main_data_dir = 'E:\\\\STACKER BEE\\\\Image classification using CNN\\\\image zip file\\\\tgv3zb82nd-1'\n",
    "samples_data_dir = 'E:\\\\STACKER BEE\\\\Image classification using CNN\\\\Sample Data'\n",
    "test_data_dir = 'E:\\\\STACKER BEE\\\\Image classification using CNN\\\\test_data'\n",
    "\n",
    "# Create test data directories\n",
    "test_dir_a = os.path.join(test_data_dir, r'E:\\STACKER BEE\\Image classification using CNN\\Test Data')\n",
    "test_dir_b = os.path.join(test_data_dir, r'E:\\STACKER BEE\\Image classification using CNN\\Test Data')\n",
    "os.makedirs(test_dir_a, exist_ok=True)\n",
    "os.makedirs(test_dir_b, exist_ok=True)\n",
    "\n",
    "# Function to select files for testing\n",
    "def select_test_files(main_dir, samples_dir, test_dir):\n",
    "    main_class_dirs = os.listdir(main_dir)\n",
    "    for class_dir in main_class_dirs:\n",
    "        main_class_path = os.path.join(main_dir, class_dir)\n",
    "        samples_class_path = os.path.join(samples_dir, class_dir)\n",
    "        test_class_path = os.path.join(test_dir, class_dir)\n",
    "        os.makedirs(test_class_path, exist_ok=True)\n",
    "\n",
    "        main_files = os.listdir(main_class_path)\n",
    "        samples_files = os.listdir(samples_class_path)\n",
    "\n",
    "        test_files = list(set(main_files) - set(samples_files))\n",
    "\n",
    "        for file in test_files:\n",
    "            src_path = os.path.join(main_class_path, file)\n",
    "            dest_path = os.path.join(test_class_path, file)\n",
    "            shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Select files for testing for classes a and b\n",
    "select_test_files(os.path.join(main_data_dir, r'E:\\STACKER BEE\\Image classification using CNN\\image zip file\\tgv3zb82nd-1\\Healthy-20210326T083815Z-001'), os.path.join(samples_data_dir, r'E:\\STACKER BEE\\Image classification using CNN\\Sample Data'), test_dir_a)\n",
    "select_test_files(os.path.join(main_data_dir,r'E:\\STACKER BEE\\Image classification using CNN\\image zip file\\tgv3zb82nd-1\\Miner-20210326T082341Z-001' ), os.path.join(samples_data_dir, r'E:\\STACKER BEE\\Image classification using CNN\\Sample Data'), test_dir_b)\n",
    "\n",
    "print(\"Test data created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8fbb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "main_data_dir = 'E:\\\\STACKER BEE\\\\Image classification using CNN\\\\image zip file\\\\tgv3zb82nd-1'\n",
    "samples_data_dir = 'E:\\\\STACKER BEE\\\\Image classification using CNN\\\\Sample Data'\n",
    "test_data_dir = 'E:\\\\STACKER BEE\\\\Image classification using CNN\\\\test_data'\n",
    "\n",
    "# Create test data directories\n",
    "test_dir_a = os.path.join(test_data_dir, r'E:\\STACKER BEE\\Image classification using CNN\\Test Data')\n",
    "test_dir_b = os.path.join(test_data_dir, r'E:\\STACKER BEE\\Image classification using CNN\\Test Data')\n",
    "os.makedirs(test_dir_a, exist_ok=True)\n",
    "os.makedirs(test_dir_b, exist_ok=True)\n",
    "\n",
    "# Function to select files for testing\n",
    "def select_test_files(main_dir, samples_dir, test_dir, num_files):\n",
    "    main_class_dirs = os.listdir(main_dir)\n",
    "    for class_dir in main_class_dirs:\n",
    "        main_class_path = os.path.join(main_dir, class_dir)\n",
    "        samples_class_path = os.path.join(samples_dir, class_dir)\n",
    "        test_class_path = os.path.join(test_dir, class_dir)\n",
    "        os.makedirs(test_class_path, exist_ok=True)\n",
    "\n",
    "        main_files = os.listdir(main_class_path)\n",
    "        samples_files = os.listdir(samples_class_path)\n",
    "\n",
    "        # Select files that are in main_files but not in samples_files\n",
    "        test_files = [file for file in main_files if file not in samples_files]\n",
    "\n",
    "        # Randomly select num_files from test_files\n",
    "        test_files = random.sample(test_files, min(num_files, len(test_files)))\n",
    "\n",
    "        for file in test_files:\n",
    "            src_path = os.path.join(main_class_path, file)\n",
    "            dest_path = os.path.join(test_class_path, file)\n",
    "            shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Number of files to select for testing from each class\n",
    "num_files = 300\n",
    "\n",
    "# Select files for testing for classes a and b\n",
    "select_test_files(os.path.join(main_data_dir, 'Healthy-20210326T083815Z-001'), samples_data_dir, test_dir_a, num_files)\n",
    "select_test_files(os.path.join(main_data_dir, 'Miner-20210326T082341Z-001'), samples_data_dir, test_dir_b, num_files)\n",
    "\n",
    "print(\"Test data created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3097a0bd",
   "metadata": {},
   "source": [
    "### Model testing on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb176001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filed saved successfully\n",
      "filed saved successfully\n"
     ]
    }
   ],
   "source": [
    "##Extracting the files and saving the names for testing the saved model\n",
    "import os\n",
    "# Define the path to the 'Healthy' folder within the main_data_dir\n",
    "healthy_folder_path = os.path.join(main_data_dir, r'E:\\STACKER BEE\\Image classification using CNN\\Test Data\\Healthy')\n",
    "miner_folder_path= os.path.join(main_data_dir, r'E:\\STACKER BEE\\Image classification using CNN\\Test Data\\Miner')\n",
    "def data_path(folder_path):\n",
    "    # Get a list of files in the 'Healthy' folder\n",
    "    healthy_files = os.listdir(healthy_folder_path)\n",
    "    files=[]\n",
    "    #Iterate through the files\n",
    "    for file_name in healthy_files:\n",
    "        file_path = os.path.join(healthy_folder_path, file_name)\n",
    "        files.append(file_path)\n",
    "    print('filed saved successfully')\n",
    "    return files\n",
    "healthy_files=data_path(healthy_folder_path)\n",
    "miner_files=data_path(miner_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad2a9c",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62e834b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'keras.src.losses.losses.BinaryCrossentropy'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.losses', 'class_name': 'BinaryCrossentropy', 'config': {'reduction': 'auto', 'name': 'binary_crossentropy', 'from_logits': False, 'label_smoothing': 0.0, 'axis': -1, 'fn': 'binary_crossentropy'}, 'registered_name': None}.\n\nException encountered: BinaryCrossentropy.__init__() got an unexpected keyword argument 'fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mE:\\STACKER BEE\\Image classification using CNN\\venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:711\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 711\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mE:\\STACKER BEE\\Image classification using CNN\\venv\\Lib\\site-packages\\keras\\src\\losses\\losses.py:34\u001b[0m, in \u001b[0;36mLossFunctionWrapper.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m     33\u001b[0m     config \u001b[38;5;241m=\u001b[39m serialization_lib\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(config)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: BinaryCrossentropy.__init__() got an unexpected keyword argument 'fn'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#set your model path\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSTACKER BEE\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mImage classification using CNN\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodel.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBinaryCrossentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mBinaryCrossentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\STACKER BEE\\Image classification using CNN\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32mE:\\STACKER BEE\\Image classification using CNN\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\STACKER BEE\\Image classification using CNN\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:143\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _resolve_compile_arguments_compat(loss, loss_config, losses)\n",
      "File \u001b[1;32mE:\\STACKER BEE\\Image classification using CNN\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:202\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[1;34m(deserialize_fn, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    205\u001b[0m         k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    207\u001b[0m     }\n",
      "File \u001b[1;32mE:\\STACKER BEE\\Image classification using CNN\\venv\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:124\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_OBJECTS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\STACKER BEE\\Image classification using CNN\\venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:576\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[0;32m    570\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    571\u001b[0m                 serialize_with_public_fn(\n\u001b[0;32m    572\u001b[0m                     module_objects[config], config, fn_module_name\n\u001b[0;32m    573\u001b[0m                 ),\n\u001b[0;32m    574\u001b[0m                 custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    575\u001b[0m             )\n\u001b[1;32m--> 576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m            \u001b[49m\u001b[43mserialize_with_public_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_config\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "File \u001b[1;32mE:\\STACKER BEE\\Image classification using CNN\\venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:713\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    711\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(inner_config)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    714\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    715\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    716\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m instances (layers, models, etc.) returned by\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `get_config()` are explicitly deserialized in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `from_config()` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    720\u001b[0m     )\n\u001b[0;32m    721\u001b[0m build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m build_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mbuilt:\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'keras.src.losses.losses.BinaryCrossentropy'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.losses', 'class_name': 'BinaryCrossentropy', 'config': {'reduction': 'auto', 'name': 'binary_crossentropy', 'from_logits': False, 'label_smoothing': 0.0, 'axis': -1, 'fn': 'binary_crossentropy'}, 'registered_name': None}.\n\nException encountered: BinaryCrossentropy.__init__() got an unexpected keyword argument 'fn'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.losses import BinaryCrossentropy\n",
    "#set your model path\n",
    "model_path=r'E:\\STACKER BEE\\Image classification using CNN\\model.h5'\n",
    "model = load_model(model_path, custom_objects={'BinaryCrossentropy': BinaryCrossentropy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8353f389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in e:\\progamfiles\\anaconda\\lib\\site-packages (2.15.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.1\n",
      "  Downloading tensorflow_intel-2.16.1-cp39-cp39-win_amd64.whl (376.9 MB)\n",
      "     ------------------------------------ 376.9/376.9 MB 351.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Collecting ml-dtypes~=0.3.1\n",
      "  Downloading ml_dtypes-0.3.2-cp39-cp39-win_amd64.whl (127 kB)\n",
      "     -------------------------------------- 127.7/127.7 kB 7.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Collecting tensorboard<2.17,>=2.16\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.60.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Collecting keras>=3.0.0\n",
      "  Using cached keras-3.1.1-py3-none-any.whl (1.1 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\progamfiles\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Collecting optree\n",
      "  Downloading optree-0.11.0-cp39-cp39-win_amd64.whl (240 kB)\n",
      "     -------------------------------------- 240.0/240.0 kB 5.0 MB/s eta 0:00:00\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\progamfiles\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\progamfiles\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\progamfiles\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\progamfiles\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\progamfiles\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in e:\\progamfiles\\anaconda\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\progamfiles\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\progamfiles\\anaconda\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, pygments, optree, ml-dtypes, mdurl, markdown-it-py, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.2.0\n",
      "    Uninstalling ml-dtypes-0.2.0:\n",
      "      Successfully uninstalled ml-dtypes-0.2.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.1\n",
      "    Uninstalling tensorboard-2.15.1:\n",
      "      Successfully uninstalled tensorboard-2.15.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.15.0\n",
      "    Uninstalling keras-2.15.0:\n",
      "      Successfully uninstalled keras-2.15.0\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.15.0\n",
      "    Uninstalling tensorflow-intel-2.15.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.15.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.15.0\n",
      "    Uninstalling tensorflow-2.15.0:\n",
      "      Successfully uninstalled tensorflow-2.15.0\n",
      "Successfully installed keras-3.1.1 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.7 optree-0.11.0 pygments-2.17.2 rich-13.7.1 tensorboard-2.16.2 tensorflow-2.16.1 tensorflow-intel-2.16.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03210c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN",
   "language": "python",
   "name": "cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
